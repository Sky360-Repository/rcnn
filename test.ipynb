{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import simple_train\n",
    "\n",
    "transform=simple_train.get_transform(train=True)\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = simple_train.PennFudanDataset('PennFudanPed', transform)\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegionProposalNetwork(\n",
      "  (anchor_generator): AnchorGenerator()\n",
      "  (head): RPNHead(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (cls_logits): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import simple_train\n",
    "model=simple_train.get_fasterrcnn_model_instance_segmentation(2)\n",
    "print(model.rpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((32,), (64,), (128,), (256,), (512,))\n",
      "((0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0))\n",
      "[3, 3, 3, 3, 3]\n",
      "[tensor([[-23., -11.,  23.,  11.],\n",
      "        [-16., -16.,  16.,  16.],\n",
      "        [-11., -23.,  11.,  23.]]), tensor([[-45., -23.,  45.,  23.],\n",
      "        [-32., -32.,  32.,  32.],\n",
      "        [-23., -45.,  23.,  45.]]), tensor([[-91., -45.,  91.,  45.],\n",
      "        [-64., -64.,  64.,  64.],\n",
      "        [-45., -91.,  45.,  91.]]), tensor([[-181.,  -91.,  181.,   91.],\n",
      "        [-128., -128.,  128.,  128.],\n",
      "        [ -91., -181.,   91.,  181.]]), tensor([[-362., -181.,  362.,  181.],\n",
      "        [-256., -256.,  256.,  256.],\n",
      "        [-181., -362.,  181.,  362.]])]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FasterRCNN' object has no attribute 'rpn_score_thresh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5f/xpj5nw5j2fbcp26wb6zg66fc0000gp/T/ipykernel_28871/4194710162.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_anchors_per_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{model.rpn_score_thresh}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rcnn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FasterRCNN' object has no attribute 'rpn_score_thresh'"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torch\n",
    "def get_rcnn():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "        pretrained=False,\n",
    "        image_mean=[0.485, 0.456, 0.406, 0.485, 0.456, 0.406],\n",
    "        image_std=[0.229, 0.224, 0.225, 0.229, 0.224, 0.225])\n",
    "    return model\n",
    "\n",
    "def get_custom_rcnn(input_channels=6,num_classes=2):\n",
    "    #anchor_sizes = ((2), (4), (8), (16), (32)) \n",
    "    anchor_sizes = ((32), (64), (128), (256), (512))\n",
    "    aspect_ratios = ((0.5, 1.0, 1.5, 3), (0.5, 1.0, 1.5, 3),\n",
    "                     (0.5, 1.0, 1.5, 3), (0.5, 1.0, 1.5, 3),\n",
    "                     (0.5, 1.0, 1.5, 3))\n",
    "    anchor_generator = AnchorGenerator(\n",
    "        sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
    "\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "        pretrained=False,\n",
    "        image_mean=[0.485, 0.456, 0.406, 0.485, 0.456, 0.406],\n",
    "        image_std=[0.229, 0.224, 0.225, 0.229, 0.224, 0.225],\n",
    "        #rpn_anchor_generator=anchor_generator,\n",
    "        trainable_backbone_layers=5)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "\n",
    "    # original\n",
    "    # (box_predictor): FastRCNNPredictor(\n",
    "    #    (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
    "    #    (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
    "    #)\n",
    "    #(box_predictor): FastRCNNPredictor(\n",
    "    #    (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
    "    #    (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
    "    #)\n",
    "\n",
    "    model.backbone.body.conv1 = torch.nn.Conv2d(input_channels, 64, kernel_size=7,\n",
    "                                                stride=2, padding=3, bias=False)\n",
    "    return model\n",
    "\n",
    "model=get_custom_rcnn()\n",
    "\n",
    "print(model.rpn.anchor_generator.sizes)\n",
    "print(model.rpn.anchor_generator.aspect_ratios)\n",
    "print(model.rpn.anchor_generator.num_anchors_per_location())\n",
    "print(model.rpn.anchor_generator.cell_anchors)\n",
    "print(f\"{model.rpn_score_thresh}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.body.conv1.weight:True\n",
      "backbone.body.layer1.0.conv1.weight:True\n",
      "backbone.body.layer1.0.conv2.weight:True\n",
      "backbone.body.layer1.0.conv3.weight:True\n",
      "backbone.body.layer1.0.downsample.0.weight:True\n",
      "backbone.body.layer1.1.conv1.weight:True\n",
      "backbone.body.layer1.1.conv2.weight:True\n",
      "backbone.body.layer1.1.conv3.weight:True\n",
      "backbone.body.layer1.2.conv1.weight:True\n",
      "backbone.body.layer1.2.conv2.weight:True\n",
      "backbone.body.layer1.2.conv3.weight:True\n",
      "backbone.body.layer2.0.conv1.weight:True\n",
      "backbone.body.layer2.0.conv2.weight:True\n",
      "backbone.body.layer2.0.conv3.weight:True\n",
      "backbone.body.layer2.0.downsample.0.weight:True\n",
      "backbone.body.layer2.1.conv1.weight:True\n",
      "backbone.body.layer2.1.conv2.weight:True\n",
      "backbone.body.layer2.1.conv3.weight:True\n",
      "backbone.body.layer2.2.conv1.weight:True\n",
      "backbone.body.layer2.2.conv2.weight:True\n",
      "backbone.body.layer2.2.conv3.weight:True\n",
      "backbone.body.layer2.3.conv1.weight:True\n",
      "backbone.body.layer2.3.conv2.weight:True\n",
      "backbone.body.layer2.3.conv3.weight:True\n",
      "backbone.body.layer3.0.conv1.weight:True\n",
      "backbone.body.layer3.0.conv2.weight:True\n",
      "backbone.body.layer3.0.conv3.weight:True\n",
      "backbone.body.layer3.0.downsample.0.weight:True\n",
      "backbone.body.layer3.1.conv1.weight:True\n",
      "backbone.body.layer3.1.conv2.weight:True\n",
      "backbone.body.layer3.1.conv3.weight:True\n",
      "backbone.body.layer3.2.conv1.weight:True\n",
      "backbone.body.layer3.2.conv2.weight:True\n",
      "backbone.body.layer3.2.conv3.weight:True\n",
      "backbone.body.layer3.3.conv1.weight:True\n",
      "backbone.body.layer3.3.conv2.weight:True\n",
      "backbone.body.layer3.3.conv3.weight:True\n",
      "backbone.body.layer3.4.conv1.weight:True\n",
      "backbone.body.layer3.4.conv2.weight:True\n",
      "backbone.body.layer3.4.conv3.weight:True\n",
      "backbone.body.layer3.5.conv1.weight:True\n",
      "backbone.body.layer3.5.conv2.weight:True\n",
      "backbone.body.layer3.5.conv3.weight:True\n",
      "backbone.body.layer4.0.conv1.weight:True\n",
      "backbone.body.layer4.0.conv2.weight:True\n",
      "backbone.body.layer4.0.conv3.weight:True\n",
      "backbone.body.layer4.0.downsample.0.weight:True\n",
      "backbone.body.layer4.1.conv1.weight:True\n",
      "backbone.body.layer4.1.conv2.weight:True\n",
      "backbone.body.layer4.1.conv3.weight:True\n",
      "backbone.body.layer4.2.conv1.weight:True\n",
      "backbone.body.layer4.2.conv2.weight:True\n",
      "backbone.body.layer4.2.conv3.weight:True\n",
      "backbone.fpn.inner_blocks.0.weight:True\n",
      "backbone.fpn.inner_blocks.0.bias:True\n",
      "backbone.fpn.inner_blocks.1.weight:True\n",
      "backbone.fpn.inner_blocks.1.bias:True\n",
      "backbone.fpn.inner_blocks.2.weight:True\n",
      "backbone.fpn.inner_blocks.2.bias:True\n",
      "backbone.fpn.inner_blocks.3.weight:True\n",
      "backbone.fpn.inner_blocks.3.bias:True\n",
      "backbone.fpn.layer_blocks.0.weight:True\n",
      "backbone.fpn.layer_blocks.0.bias:True\n",
      "backbone.fpn.layer_blocks.1.weight:True\n",
      "backbone.fpn.layer_blocks.1.bias:True\n",
      "backbone.fpn.layer_blocks.2.weight:True\n",
      "backbone.fpn.layer_blocks.2.bias:True\n",
      "backbone.fpn.layer_blocks.3.weight:True\n",
      "backbone.fpn.layer_blocks.3.bias:True\n",
      "rpn.head.conv.weight:True\n",
      "rpn.head.conv.bias:True\n",
      "rpn.head.cls_logits.weight:True\n",
      "rpn.head.cls_logits.bias:True\n",
      "rpn.head.bbox_pred.weight:True\n",
      "rpn.head.bbox_pred.bias:True\n",
      "roi_heads.box_head.fc6.weight:True\n",
      "roi_heads.box_head.fc6.bias:True\n",
      "roi_heads.box_head.fc7.weight:True\n",
      "roi_heads.box_head.fc7.bias:True\n",
      "roi_heads.box_predictor.cls_score.weight:True\n",
      "roi_heads.box_predictor.cls_score.bias:True\n",
      "roi_heads.box_predictor.bbox_pred.weight:True\n",
      "roi_heads.box_predictor.bbox_pred.bias:True\n",
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406, 0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225, 0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cls_logits): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}:{param.requires_grad}\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(f\"{name}, {parameter.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params += param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "\n",
    "count_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#for name, layer in model.named_parameters():\n",
    "#    print(f\"{name}, {layer.size()}\")\n",
    "#    model[name] = torch.nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(\n",
    "#        2, 2), padding=(3, 3), bias=False)\n",
    "model.backbone.body.conv1 = torch.nn.Conv2d(4, 64, kernel_size=7,\n",
    "                        stride=2, padding=3, bias=False)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from engine import train_one_epoch, evaluate\n",
    "import simple_train\n",
    "import os\n",
    "import utils\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "dataset_test = simple_train.PesmodOpticalFlowDataset(\n",
    "    os.path.join('PESMOD', 'train'), simple_train.get_transform(train=False)) # !!actually training data\n",
    "indices = torch.randperm(len(dataset_test)).tolist()\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[:50])\n",
    "print(f\"test set size: {len(dataset_test)}\")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "model = simple_train.get_fasterrcnn_model(input_channels=6, classes=2)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rcnn]",
   "language": "python",
   "name": "conda-env-rcnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
