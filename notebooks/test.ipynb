{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import simple_train\n",
    "\n",
    "transform=simple_train.get_transform(train=True)\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = simple_train.PennFudanDataset('PennFudanPed', transform)\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simple_train\n",
    "model=simple_train.get_fasterrcnn_model_instance_segmentation(2)\n",
    "print(model.rpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torch\n",
    "def get_rcnn():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "        pretrained=False,\n",
    "        image_mean=[0.485, 0.456, 0.406, 0.485, 0.456, 0.406],\n",
    "        image_std=[0.229, 0.224, 0.225, 0.229, 0.224, 0.225])\n",
    "    return model\n",
    "\n",
    "def get_custom_rcnn(input_channels=6,num_classes=2):\n",
    "    #anchor_sizes = ((2), (4), (8), (16), (32)) \n",
    "    anchor_sizes = ((32), (64), (128), (256), (512))\n",
    "    aspect_ratios = ((0.5, 1.0, 1.5, 3), (0.5, 1.0, 1.5, 3),\n",
    "                     (0.5, 1.0, 1.5, 3), (0.5, 1.0, 1.5, 3),\n",
    "                     (0.5, 1.0, 1.5, 3))\n",
    "    anchor_generator = AnchorGenerator(\n",
    "        sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
    "\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "        pretrained=False,\n",
    "        image_mean=[0.485, 0.456, 0.406, 0.485, 0.456, 0.406],\n",
    "        image_std=[0.229, 0.224, 0.225, 0.229, 0.224, 0.225],\n",
    "        #rpn_anchor_generator=anchor_generator,\n",
    "        trainable_backbone_layers=5)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "\n",
    "    # original\n",
    "    # (box_predictor): FastRCNNPredictor(\n",
    "    #    (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
    "    #    (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
    "    #)\n",
    "    #(box_predictor): FastRCNNPredictor(\n",
    "    #    (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
    "    #    (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
    "    #)\n",
    "\n",
    "    model.backbone.body.conv1 = torch.nn.Conv2d(input_channels, 64, kernel_size=7,\n",
    "                                                stride=2, padding=3, bias=False)\n",
    "    return model\n",
    "\n",
    "model=get_custom_rcnn()\n",
    "\n",
    "print(model.rpn.anchor_generator.sizes)\n",
    "print(model.rpn.anchor_generator.aspect_ratios)\n",
    "print(model.rpn.anchor_generator.num_anchors_per_location())\n",
    "print(model.rpn.anchor_generator.cell_anchors)\n",
    "print(f\"{model.rpn_score_thresh}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}:{param.requires_grad}\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(f\"{name}, {parameter.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params += param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "\n",
    "count_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#for name, layer in model.named_parameters():\n",
    "#    print(f\"{name}, {layer.size()}\")\n",
    "#    model[name] = torch.nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(\n",
    "#        2, 2), padding=(3, 3), bias=False)\n",
    "model.backbone.body.conv1 = torch.nn.Conv2d(4, 64, kernel_size=7,\n",
    "                        stride=2, padding=3, bias=False)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from engine import train_one_epoch, evaluate\n",
    "import simple_train\n",
    "import os\n",
    "import utils\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "dataset_test = simple_train.PesmodOpticalFlowDataset(\n",
    "    os.path.join('PESMOD', 'train'), simple_train.get_transform(train=False)) # !!actually training data\n",
    "indices = torch.randperm(len(dataset_test)).tolist()\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[:50])\n",
    "print(f\"test set size: {len(dataset_test)}\")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "model = simple_train.get_fasterrcnn_model(input_channels=6, classes=2)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rcnn]",
   "language": "python",
   "name": "conda-env-rcnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
